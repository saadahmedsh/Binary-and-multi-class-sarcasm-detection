{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarcasm_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMANxuOgSx3aOPmhD+GHgfK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadahmedsh/Binary-and-multi-class-sarcasm-detection/blob/main/sarcasm_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_l8X9JLH7HL"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, layers, callbacks\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, SimpleRNN\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from numpy import asarray\n",
        "from numpy import zeros"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upload=files.upload()"
      ],
      "metadata": {
        "id": "ehtuz81CdYys",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "86833874-db78-4a82-e26c-d24c18d9dc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a59adaaf-b76e-4a19-b2b6-760318f13add\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a59adaaf-b76e-4a19-b2b6-760318f13add\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Sarcasm Dataset.csv to Sarcasm Dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"Sarcasm Dataset.csv\")"
      ],
      "metadata": {
        "id": "z4fALBisdx4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'] = df['tweet'].apply(lambda s : re.sub('[^a-zA-Z]', ' ', str(s)))\n",
        "stemmer = PorterStemmer()\n",
        "df['tweet'] = df['tweet'].apply(lambda x: x.split())\n",
        "df['tweet'] = df['tweet'].apply(lambda x : ' '.join([stemmer.stem(word) for word in x]))"
      ],
      "metadata": {
        "id": "behnHlx0d3kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers=[2,3]\n",
        "dropout=[0.3 , 0.7]\n",
        "layer_types = [SimpleRNN, LSTM, GRU]"
      ],
      "metadata": {
        "id": "7TzybXDPfPJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 2200\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(df['tweet'].values)\n",
        "X = tokenizer.texts_to_sequences(df['tweet'].values)\n",
        "X = pad_sequences(X)"
      ],
      "metadata": {
        "id": "kQbhgRUhmSHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(df['sarcastic']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.75, random_state = 42)\n"
      ],
      "metadata": {
        "id": "2Va39jQoIJNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sarcastic'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pJzNzVuHYrb",
        "outputId": "bdd0348b-286c-4272-8874-944ed28aa789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2601\n",
              "1     867\n",
              "Name: sarcastic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_predicted_values(dropout, layers, layer_type, output_neurons):\n",
        "  dimensions = 58\n",
        "  neurons = 196\n",
        "  batch_size = 32\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Embedding(max_features, dimensions,input_length = X.shape[1]))\n",
        " \n",
        "  model.add(SpatialDropout1D(0.4))\n",
        "  for i in range(0, layers-1):\n",
        "    model.add(layer_type(neurons, dropout=dropout, recurrent_dropout=dropout, return_sequences=True))\n",
        "\n",
        "  model.add(layer_type(neurons, dropout=dropout, recurrent_dropout=dropout))\n",
        "  model.add(Dense(output_neurons,activation='softmax'))\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        " \n",
        "  lstm_train = model.fit(X_train, Y_train, epochs = 5, batch_size=batch_size, verbose = 0)\n",
        " \n",
        "  values= model.predict(X_test)\n",
        "  values[values> 0.5] = 1\n",
        "  values[values <= 0.5] = 0\n",
        "  print(\"......... Dropout :\" + str(dropout) + \" Layers: \" + str(layers) + \" Model type: \" + str(layer_type) + \" ........\")\n",
        "  print(\".......................................................\")\n",
        "  print(classification_report(Y_test, values))"
      ],
      "metadata": {
        "id": "eDuJSh1CK4xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('........ Binary Classification .......')\n",
        "for num_layers in layers:\n",
        "  for drop in dropout:\n",
        "    for _layer in layer_types:\n",
        "      score_predicted_values(drop, num_layers, _layer, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxzIsJByIMrf",
        "outputId": "6fefca2e-29a5-4eef-ee8c-8f3113aa5fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "........ Binary Classification .......\n",
            "......... Dropout :0.3 Layers: 2 Model type: <class 'keras.layers.recurrent.SimpleRNN'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86      1951\n",
            "           1       0.00      0.00      0.00       650\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2601\n",
            "   macro avg       0.38      0.50      0.43      2601\n",
            "weighted avg       0.56      0.75      0.64      2601\n",
            " samples avg       0.75      0.75      0.75      2601\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 2 Model type: <class 'keras.layers.recurrent_v2.LSTM'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.98      0.85      1951\n",
            "           1       0.39      0.03      0.06       650\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2601\n",
            "   macro avg       0.57      0.51      0.46      2601\n",
            "weighted avg       0.66      0.75      0.66      2601\n",
            " samples avg       0.75      0.75      0.75      2601\n",
            "\n",
            "......... Dropout :0.3 Layers: 2 Model type: <class 'keras.layers.recurrent_v2.GRU'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.90      0.82      1951\n",
            "           1       0.32      0.14      0.19       650\n",
            "\n",
            "   micro avg       0.71      0.71      0.71      2601\n",
            "   macro avg       0.54      0.52      0.51      2601\n",
            "weighted avg       0.65      0.71      0.67      2601\n",
            " samples avg       0.71      0.71      0.71      2601\n",
            "\n",
            "......... Dropout :0.7 Layers: 2 Model type: <class 'keras.layers.recurrent.SimpleRNN'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86      1951\n",
            "           1       0.00      0.00      0.00       650\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2601\n",
            "   macro avg       0.38      0.50      0.43      2601\n",
            "weighted avg       0.56      0.75      0.64      2601\n",
            " samples avg       0.75      0.75      0.75      2601\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 2 Model type: <class 'keras.layers.recurrent_v2.LSTM'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.99      0.85      1951\n",
            "           1       0.32      0.02      0.03       650\n",
            "\n",
            "   micro avg       0.74      0.74      0.74      2601\n",
            "   macro avg       0.53      0.50      0.44      2601\n",
            "weighted avg       0.64      0.74      0.65      2601\n",
            " samples avg       0.74      0.74      0.74      2601\n",
            "\n",
            "......... Dropout :0.7 Layers: 2 Model type: <class 'keras.layers.recurrent_v2.GRU'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86      1951\n",
            "           1       1.00      0.00      0.01       650\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2601\n",
            "   macro avg       0.88      0.50      0.43      2601\n",
            "weighted avg       0.81      0.75      0.64      2601\n",
            " samples avg       0.75      0.75      0.75      2601\n",
            "\n",
            "......... Dropout :0.3 Layers: 3 Model type: <class 'keras.layers.recurrent.SimpleRNN'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86      1951\n",
            "           1       0.00      0.00      0.00       650\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2601\n",
            "   macro avg       0.38      0.50      0.43      2601\n",
            "weighted avg       0.56      0.75      0.64      2601\n",
            " samples avg       0.75      0.75      0.75      2601\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 3 Model type: <class 'keras.layers.recurrent_v2.LSTM'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.95      0.84      1951\n",
            "           1       0.34      0.08      0.12       650\n",
            "\n",
            "   micro avg       0.73      0.73      0.73      2601\n",
            "   macro avg       0.55      0.51      0.48      2601\n",
            "weighted avg       0.65      0.73      0.66      2601\n",
            " samples avg       0.73      0.73      0.73      2601\n",
            "\n",
            "......... Dropout :0.3 Layers: 3 Model type: <class 'keras.layers.recurrent_v2.GRU'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.77      0.77      1951\n",
            "           1       0.30      0.30      0.30       650\n",
            "\n",
            "   micro avg       0.65      0.65      0.65      2601\n",
            "   macro avg       0.53      0.53      0.53      2601\n",
            "weighted avg       0.65      0.65      0.65      2601\n",
            " samples avg       0.65      0.65      0.65      2601\n",
            "\n",
            "......... Dropout :0.7 Layers: 3 Model type: <class 'keras.layers.recurrent.SimpleRNN'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86      1951\n",
            "           1       0.00      0.00      0.00       650\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2601\n",
            "   macro avg       0.38      0.50      0.43      2601\n",
            "weighted avg       0.56      0.75      0.64      2601\n",
            " samples avg       0.75      0.75      0.75      2601\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 3 Model type: <class 'keras.layers.recurrent_v2.LSTM'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86      1951\n",
            "           1       0.00      0.00      0.00       650\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2601\n",
            "   macro avg       0.38      0.50      0.43      2601\n",
            "weighted avg       0.56      0.75      0.64      2601\n",
            " samples avg       0.75      0.75      0.75      2601\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 3 Model type: <class 'keras.layers.recurrent_v2.GRU'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.98      0.85      1951\n",
            "           1       0.26      0.02      0.03       650\n",
            "\n",
            "   micro avg       0.74      0.74      0.74      2601\n",
            "   macro avg       0.51      0.50      0.44      2601\n",
            "weighted avg       0.63      0.74      0.65      2601\n",
            " samples avg       0.74      0.74      0.74      2601\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_predicted_values_bidirectional(dropout, layers, output_neurons):\n",
        "  dimensions = 58\n",
        "  neurons = 196\n",
        "  batch_size = 32\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(max_features, dimensions,input_length = X.shape[1]))\n",
        "  \n",
        "  model.add(SpatialDropout1D(0.4))\n",
        "  for i in range(0, layers-1):\n",
        "    model.add(Bidirectional(LSTM(neurons, return_sequences=True, recurrent_dropout=dropout, dropout=dropout)))\n",
        "  model.add(Bidirectional(LSTM(neurons, recurrent_dropout=dropout, dropout=dropout)))\n",
        "  model.add(Dense(output_neurons,activation='softmax'))\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "  lstm_train = model.fit(X_train, Y_train, epochs = 5, batch_size=batch_size, verbose = 0)\n",
        "  values= model.predict(X_test)\n",
        "  values[values> 0.5] = 1\n",
        "  values[values <= 0.5] = 0\n",
        "  print(\"......... Dropout :\" + str(dropout) + \" Layers: \" + str(layers) + \" Model type: \" + \"Bidirectional\" + \" ........\")\n",
        "  print(\".......................................................\")\n",
        "  print(classification_report(Y_test, values))"
      ],
      "metadata": {
        "id": "wwk72NEuIS7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for num_layers in layers:\n",
        "  for drop in dropout:\n",
        "    score_predicted_values_bidirectional(drop, num_layers, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbSpfjw3Pj5l",
        "outputId": "85fd7e20-8eb5-40be-b7e5-64053262e8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 2 Model type: Bidirectional ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.90      0.82      1951\n",
            "           1       0.34      0.16      0.21       650\n",
            "\n",
            "   micro avg       0.71      0.71      0.71      2601\n",
            "   macro avg       0.55      0.53      0.52      2601\n",
            "weighted avg       0.66      0.71      0.67      2601\n",
            " samples avg       0.71      0.71      0.71      2601\n",
            "\n",
            "......... Dropout :0.7 Layers: 2 Model type: Bidirectional ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.96      0.84      1951\n",
            "           1       0.29      0.05      0.09       650\n",
            "\n",
            "   micro avg       0.73      0.73      0.73      2601\n",
            "   macro avg       0.52      0.50      0.46      2601\n",
            "weighted avg       0.64      0.73      0.65      2601\n",
            " samples avg       0.73      0.73      0.73      2601\n",
            "\n",
            "......... Dropout :0.3 Layers: 3 Model type: Bidirectional ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.86      0.81      1951\n",
            "           1       0.34      0.21      0.26       650\n",
            "\n",
            "   micro avg       0.70      0.70      0.70      2601\n",
            "   macro avg       0.55      0.54      0.54      2601\n",
            "weighted avg       0.66      0.70      0.67      2601\n",
            " samples avg       0.70      0.70      0.70      2601\n",
            "\n",
            "......... Dropout :0.7 Layers: 3 Model type: Bidirectional ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86      1951\n",
            "           1       0.00      0.00      0.00       650\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2601\n",
            "   macro avg       0.38      0.50      0.43      2601\n",
            "weighted avg       0.56      0.75      0.64      2601\n",
            " samples avg       0.75      0.75      0.75      2601\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sarcastic_df=df.copy()"
      ],
      "metadata": {
        "id": "ssixVOccsH8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sarcastic_df['labels']=[0] * len(sarcastic_df)\n",
        "columns=['rhetorical_question', 'overstatement', 'understatement',\n",
        "       'satire', 'irony', 'sarcasm']\n",
        "for i in range(0, len(columns)):\n",
        "  sarcastic_df['labels'] = np.where((sarcastic_df[columns[i]] == 1),(len(columns) - i),sarcastic_df['labels'])\n",
        "\n",
        "sarcastic_df=sarcastic_df.iloc[np.where(df['sarcastic'] == 1)].dropna()"
      ],
      "metadata": {
        "id": "EHkUm474sUdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding=[[1,0,0,0,0,0], [0,1,0,0,0,0], [0,0,1,0,0,0],[0,0,0,1,0,0],[0,0,0,0,1,0],[0,0,0,0,0,1]]"
      ],
      "metadata": {
        "id": "NhbDhYHLt6XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=[]\n",
        "features=sarcastic_df['tweet']\n",
        "for index, row in sarcastic_df.iterrows():\n",
        "  labels.append(encoding[row['labels'] - 1])\n"
      ],
      "metadata": {
        "id": "Ap2WJsdzu__C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(features)\n",
        "X = tokenizer.texts_to_sequences(features)\n",
        "X = pad_sequences(X)"
      ],
      "metadata": {
        "id": "2suNfebQzkSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,labels, test_size = 0.25, random_state = 42)\n",
        "Y_train=np.array(Y_train)\n",
        "Y_test=np.array(Y_test)"
      ],
      "metadata": {
        "id": "_dOrCMZPz1Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('........ Multi Classification .......')\n",
        "for num_layers in layers:\n",
        "  for drop in dropout:\n",
        "    for _layer in layer_types:\n",
        "      score_predicted_values(drop, num_layers, _layer, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE87LiIW1wsD",
        "outputId": "fd15b260-e2ed-4fe2-ac99-ec174ae4c1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "........ Multi Classification .......\n",
            "......... Dropout :0.3 Layers: 2 Model type: <class 'keras.layers.recurrent.SimpleRNN'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 2 Model type: <class 'keras.layers.recurrent_v2.LSTM'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 2 Model type: <class 'keras.layers.recurrent_v2.GRU'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       185\n",
            "           1       0.11      0.03      0.05        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.82      0.82      0.82       217\n",
            "   macro avg       0.16      0.16      0.16       217\n",
            "weighted avg       0.74      0.82      0.78       217\n",
            " samples avg       0.82      0.82      0.82       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 2 Model type: <class 'keras.layers.recurrent.SimpleRNN'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.99      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.84      0.85       217\n",
            "   macro avg       0.14      0.16      0.15       217\n",
            "weighted avg       0.73      0.84      0.78       217\n",
            " samples avg       0.84      0.84      0.84       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 2 Model type: <class 'keras.layers.recurrent_v2.LSTM'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 2 Model type: <class 'keras.layers.recurrent_v2.GRU'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 3 Model type: <class 'keras.layers.recurrent.SimpleRNN'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 3 Model type: <class 'keras.layers.recurrent_v2.LSTM'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 3 Model type: <class 'keras.layers.recurrent_v2.GRU'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.81      0.81      0.81       217\n",
            "   macro avg       0.14      0.16      0.15       217\n",
            "weighted avg       0.72      0.81      0.76       217\n",
            " samples avg       0.81      0.81      0.81       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 3 Model type: <class 'keras.layers.recurrent.SimpleRNN'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 3 Model type: <class 'keras.layers.recurrent_v2.LSTM'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 3 Model type: <class 'keras.layers.recurrent_v2.GRU'> ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for num_layers in layers:\n",
        "  for drop in dropout:\n",
        "    score_predicted_values_bidirectional(drop, num_layers, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoZGVatT2dbj",
        "outputId": "7638d4f8-c58b-4586-b86e-25175586a181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 2 Model type: Bidirectional ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 2 Model type: Bidirectional ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.85      0.85       217\n",
            "   macro avg       0.14      0.17      0.15       217\n",
            "weighted avg       0.73      0.85      0.78       217\n",
            " samples avg       0.85      0.85      0.85       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 3 Model type: Bidirectional ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84       185\n",
            "           1       0.11      0.12      0.12        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.73      0.72      0.73       217\n",
            "   macro avg       0.16      0.16      0.16       217\n",
            "weighted avg       0.74      0.72      0.73       217\n",
            " samples avg       0.72      0.72      0.72       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.7 Layers: 3 Model type: Bidirectional ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.99      0.92       185\n",
            "           1       0.00      0.00      0.00        32\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.85      0.84      0.85       217\n",
            "   macro avg       0.14      0.16      0.15       217\n",
            "weighted avg       0.73      0.84      0.78       217\n",
            " samples avg       0.84      0.84      0.84       217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################## Question 2 ########################\n",
        "# GLOVE\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rak0kF0i_a9b",
        "outputId": "881fbd29-51ec-4d6f-d46e-bede23565337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-09 04:32:27--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-05-09 04:32:27--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-05-09 04:32:27--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.18MB/s    in 2m 40s  \n",
            "\n",
            "2022-05-09 04:35:08 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7tnT2PsFZzz",
        "outputId": "4d965bc2-327e-4065-e920-bb5877380690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets=df['tweet']\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(tweets)\n",
        "vocab_size = len(token.word_index) + 1\n",
        "encoded_tweet = token.texts_to_sequences(tweets)"
      ],
      "metadata": {
        "id": "ie0wV8flP8Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=len(max(encoded_tweet, key=len))\n",
        "padded_tweet = pad_sequences(encoded_tweet, maxlen=max_len, padding='post')"
      ],
      "metadata": {
        "id": "VYkUY9eMQc7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index_glove = dict()\n",
        "f = open('glove.6B.50d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\n",
        "\tword = values[0]  \n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index_glove[word] = coefs\n",
        "f.close()"
      ],
      "metadata": {
        "id": "cPqOm5XoQ2d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embedding_matrix(embed):\n",
        "  embedding_matrix = zeros((vocab_size, 50))\n",
        "  for word, i in token.word_index.items():\n",
        "\t  embedding_vector = embed.get(word)\n",
        "\t  if embedding_vector is not None:\n",
        "\t\t  embedding_matrix[i] = embedding_vector\n",
        "  return embedding_matrix\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "lz4tN6Q1ayo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(padded_tweet,df['sarcastic'], test_size = 0.25, random_state = 42)"
      ],
      "metadata": {
        "id": "0gUplKacX-eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimal_model(embedding_matrix, vocab, length):\n",
        "  model = Sequential()\n",
        "  embed = Embedding(vocab,length, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
        "  model.add(embed)\n",
        "  model.add(SimpleRNN(58, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
        "  model.add(SimpleRNN(58, dropout=0.3, recurrent_dropout=0.3))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(X_train, Y_train, epochs=10, verbose=0)\n",
        "  values= model.predict(X_test)\n",
        "  values[values> 0.5] = 1\n",
        "  values[values <= 0.5] = 0\n",
        "  print(\"......... Dropout :\" + str(0.3) + \" Layers: \" + str(2) + \" Model type: \" + str(\"RNN\") + \" ........\")\n",
        "  print(\".......................................................\")\n",
        "  print(classification_report(Y_test, values))\n",
        "\n"
      ],
      "metadata": {
        "id": "3A2fxF2OR0LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimal Parameter with Glove\n",
        "optimal_model(generate_embedding_matrix(embeddings_index_glove), vocab_size, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQT9i1Ek8V-D",
        "outputId": "23801a1a-ac05-46bb-dd2c-7f643fef5bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 2 Model type: RNN ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      1.00      0.83       620\n",
            "           1       0.00      0.00      0.00       247\n",
            "\n",
            "    accuracy                           0.72       867\n",
            "   macro avg       0.36      0.50      0.42       867\n",
            "weighted avg       0.51      0.72      0.60       867\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word2Vec\n",
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "tab4DOomTakw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processedLines = [gensim.utils.simple_preprocess(sentence) for sentence in df['tweet']]\n",
        "word_list = [word for words in processedLines for word in words]"
      ],
      "metadata": {
        "id": "v2OKbMxyZYTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(\n",
        "    [word_list],\n",
        "    negative=10,\n",
        "    iter=50,\n",
        "    min_count=1,\n",
        "    size=50 #dimension of the word vector\n",
        "    )"
      ],
      "metadata": {
        "id": "f0YX0k5ZWy1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee529cd1-dfa6-48ca-fcc5-151cc17a94ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index_word_vec = dict()\n",
        "for word in word_list:\n",
        "  embeddings_index_word_vec[word]=model[word]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy30fAnOZA17",
        "outputId": "dd18ad2e-8e1a-4894-ce62-16f0f0b75d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimal Parameter with Word2Vec\n",
        "optimal_model(generate_embedding_matrix(embeddings_index_word_vec), vocab_size, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFucGbU8bqQu",
        "outputId": "993141a7-061d-4048-e5d1-82625d39a913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 2 Model type: RNN ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      1.00      0.83       620\n",
            "           1       0.00      0.00      0.00       247\n",
            "\n",
            "    accuracy                           0.72       867\n",
            "   macro avg       0.36      0.50      0.42       867\n",
            "weighted avg       0.51      0.72      0.60       867\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "tOCVY0FJOnTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fasttext\n",
        "from gensim.models.fasttext import FastText"
      ],
      "metadata": {
        "id": "0L_cF62EbwON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_punctuation_tokenizer = nltk.WordPunctTokenizer()\n",
        "word_tokenized_corpus = [word_punctuation_tokenizer.tokenize(sent) for sent in df['tweet']]"
      ],
      "metadata": {
        "id": "QkCNMha5Oudi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 50\n",
        "window_size = 40\n",
        "min_word = 5\n",
        "down_sampling = 1e-2\n",
        "\n",
        "embeddings_fasttext = FastText(word_tokenized_corpus,\n",
        "                      size=embedding_size,\n",
        "                      window=window_size,\n",
        "                      min_count=min_word,\n",
        "                      sample=down_sampling,\n",
        "                      workers = 4,\n",
        "                      sg=1,\n",
        "                      iter=100)"
      ],
      "metadata": {
        "id": "EYas1F2_gxvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1644efb7-5567-4791-98ce-1c97ee37cd1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_buffer=[0] * 50"
      ],
      "metadata": {
        "id": "vZq_banHKauE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index_fasttext = {}\n",
        "i=0\n",
        "for sentence in word_tokenized_corpus:\n",
        "  for word in sentence:\n",
        "    try:\n",
        "      embeddings_index_fasttext[word]=embeddings_fasttext.wv[sentence][i]\n",
        "    except:\n",
        "       embeddings_index_fasttext[word]=zero_buffer\n",
        "    i+=1\n",
        "  i=0\n",
        "\n"
      ],
      "metadata": {
        "id": "yGshJq_zJYcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimal model for fasttext\n",
        "optimal_model(generate_embedding_matrix(embeddings_index_fasttext), vocab_size, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1IThZBZJtGv",
        "outputId": "757b82e4-5e53-4003-b744-6fd47536e38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 2 Model type: RNN ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      1.00      0.83       620\n",
            "           1       0.00      0.00      0.00       247\n",
            "\n",
            "    accuracy                           0.72       867\n",
            "   macro avg       0.36      0.50      0.42       867\n",
            "weighted avg       0.51      0.72      0.60       867\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Elmo\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "iFVFQDG_YSWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elmo = hub.load(\"https://tfhub.dev/google/Wiki-words-250/2\")"
      ],
      "metadata": {
        "id": "9X5pydIrZ68-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = elmo(df['tweet'].tolist())"
      ],
      "metadata": {
        "id": "nTPixQeRZ9Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n"
      ],
      "metadata": {
        "id": "EqAa0_uvchsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=np.array(embeddings)"
      ],
      "metadata": {
        "id": "t_h8PueBdDK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_zeros(arr, number):\n",
        "  new_arr=arr.copy()\n",
        "  for i in range(len(arr), number):\n",
        "    new_arr.append(0)\n",
        "  \n",
        "  return np.array(new_arr)\n"
      ],
      "metadata": {
        "id": "6gdgmV_Y1iGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_buffer=[]\n",
        "for i in range(0, len(embeddings)):\n",
        "  try:\n",
        "    embed_buffer.append(pad_zeros(embeddings[i].tolist(), len(df['tweet'][i].split(' ')) * 50).reshape(len(df['tweet'][i].split(' ')),50))\n",
        "  except:\n",
        "    # ignoring some sentences\n",
        "   embed_buffer.append(embeddings[i][0:len(df['tweet'][i].split(' ')) * 50 ])\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "gncYRrcJ6iB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index_elmo=dict()\n",
        "sentence_index=0\n",
        "for sentence in df['tweet']:\n",
        "  sentence_arr=sentence.split(' ')\n",
        "  for index in (0, len(embed_buffer[sentence_index])):\n",
        "    try:\n",
        "      embeddings_index_elmo[sentence_arr[index]]=embed_buffer[sentence_index][index]\n",
        "    except:\n",
        "      print(sentence_index,index)\n",
        "  sentence_index=+1\n",
        "      \n"
      ],
      "metadata": {
        "id": "v3qlDBV51Cos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimal Model ELMO\n",
        "\n",
        "optimal_model(generate_embedding_matrix(embeddings_index_elmo), vocab_size, 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRLph9Q7dFmX",
        "outputId": "6acc4ec2-85bd-4f5f-88e7-d21757b069da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......... Dropout :0.3 Layers: 2 Model type: RNN ........\n",
            ".......................................................\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      1.00      0.83       620\n",
            "           1       0.00      0.00      0.00       247\n",
            "\n",
            "    accuracy                           0.72       867\n",
            "   macro avg       0.36      0.50      0.42       867\n",
            "weighted avg       0.51      0.72      0.60       867\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}